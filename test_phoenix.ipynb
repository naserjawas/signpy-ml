{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naserjawas/signpy-ml/blob/main/test_phoenix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test ASLR System using RWTH Phoenix Dataset\n",
        "\n",
        "Author: Naser Jawas\n",
        "\n",
        "Created date: 1 August 2024"
      ],
      "metadata": {
        "id": "loPzn98gX6J7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEVQKTLNEoHy"
      },
      "source": [
        "### Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pllF_ivlEL8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ab2c7c-e86c-480c-d88e-dd45f1d2ea0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEnoID7rE829"
      },
      "source": [
        "### Import Files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the pre-trained files from google drive"
      ],
      "metadata": {
        "id": "i-SULtr__XS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrH9_BSoFECg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228c6168-6c42-4dc9-87ac-8d555eeb31e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/classifiers/j10clf1_50b' -> '/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_50b'\n",
            "'/content/drive/MyDrive/classifiers/j10clf1_50f' -> '/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_50f'\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/dataset/RWTHPHOENIXWeather2014/classifiers/\n",
        "!cp -v /content/drive/MyDrive/classifiers/j10clf1_30[b,f] /content/dataset/RWTHPHOENIXWeather2014/classifiers/\n",
        "!cp -v /content/drive/MyDrive/classifiers/j10clf1_50[b,f] /content/dataset/RWTHPHOENIXWeather2014/classifiers/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy ngram files"
      ],
      "metadata": {
        "id": "ZVRCmZQ5_dyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/dataset/RWTHPHOENIXWeather2014/ngram_files/\n",
        "!cp -v /content/drive/MyDrive/ngram_files/* /content/dataset/RWTHPHOENIXWeather2014/ngram_files/"
      ],
      "metadata": {
        "id": "w9nzTPot_g60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "5FGelzymJWCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle"
      ],
      "metadata": {
        "id": "bWR4Q5U7JU7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "1vdp3tszJaf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_clf(drive, glosstype, glossp, mhitype, limitsample):\n",
        "    rootdir = drive + f\"/classifiers/\"\n",
        "    filename = rootdir + f\"j{limitsample}clf{glosstype}_{glossp}{mhitype}\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(\"Classifier:\", filename, \"does not exist\")\n",
        "        exit()\n",
        "    print(filename)\n",
        "    with open(filename, 'rb') as pf:\n",
        "        clfobj = pickle.load(pf)\n",
        "    print(filename, \"loaded...\")\n",
        "    print(clfobj)\n",
        "\n",
        "    return clfobj"
      ],
      "metadata": {
        "id": "l4-lb1boJcu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Settings"
      ],
      "metadata": {
        "id": "e8xqEh0vJ3ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive = \"/content/dataset/RWTHPHOENIXWeather2014\""
      ],
      "metadata": {
        "id": "dodnEaMeJ6EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main\n",
        "\n",
        "The first step is to load the pre-trained classifier."
      ],
      "metadata": {
        "id": "3Nb3o6gnJhyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf30 = load_clf(drive, 1, 30, 'f', 10)\n",
        "cb30 = load_clf(drive, 1, 30, 'b', 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpJwkLfZJLSX",
        "outputId": "4029d222-b9a3-4014-958e-7b7d575805f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_30f\n",
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_30f loaded...\n",
            "RandomForestClassifier(n_estimators=1000, random_state=0)\n",
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_30b\n",
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_30b loaded...\n",
            "RandomForestClassifier(n_estimators=1000, random_state=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf50 = load_clf(drive, 1, 50, 'f', 10)\n",
        "cb50 = load_clf(drive, 1, 50, 'b', 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66LOBapXcOa4",
        "outputId": "1c24d9a7-b9f5-4be1-9885-ccccd85cae6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_50f\n",
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_50f loaded...\n",
            "RandomForestClassifier(n_estimators=1000, random_state=0)\n",
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_50b\n",
            "/content/dataset/RWTHPHOENIXWeather2014/classifiers/j10clf1_50b loaded...\n",
            "RandomForestClassifier(n_estimators=1000, random_state=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second step is to load n-gram objects."
      ],
      "metadata": {
        "id": "b5xqcOtF4KwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "\n",
        "with open(\"/content/dataset/RWTHPHOENIXWeather2014/ngram_files/phoenix_{n}grams\") as pf:\n",
        "    ngrams = pickle.load(pf)\n",
        "pf.close()"
      ],
      "metadata": {
        "id": "dC03NdmM4vqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The third step is to load segments object."
      ],
      "metadata": {
        "id": "FpaX0Own4qDN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-U-ECi3i4ww1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recognition proces"
      ],
      "metadata": {
        "id": "MhjQ40FymXGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datanamespart = datanames[1:2]"
      ],
      "metadata": {
        "id": "fuSGNOrkmcCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalresults = []\n",
        "for dataname_i, dataname in enumerate(datanamespart):\n",
        "    # load original data frames\n",
        "    dataloc = datadir + dataname + f\"/1/*-0.png\"\n",
        "    datafiles = sorted(glob.glob(dataloc))\n",
        "    lendatafiles = len(datafiles)\n",
        "    print(\"(\", dataname_i + 1, \"/\", len(datanamespart),\")\",\n",
        "          dataname, \"has\", lendatafiles, \"frames\")\n",
        "    imgori = [cv.imread(filename, cv.IMREAD_COLOR)\n",
        "              for filename in datafiles]\n",
        "    dataori = [cv.resize(img, (iw, ih))\n",
        "               for img in imgori]\n",
        "    peaks = alldata[dataname]\n",
        "    peaks.insert(0, 0)\n",
        "    peaks.append(lendatafiles-1)\n",
        "    allmcm = load_allmcm_video(datadir, dataname, glosstype, glossp, blankframe)\n",
        "    glossresult1 = []\n",
        "\n",
        "    glossresult1 = find_path(dataori, dataname, glossresult1, ngrams, peaks, cw, allmcm, cf, cb)\n",
        "    listgloss = [g[0] for g in glossresult1]\n",
        "    finalresults.append((dataname, listgloss))"
      ],
      "metadata": {
        "id": "WDDg9i2ZmfdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the results"
      ],
      "metadata": {
        "id": "aRxBLjK41PPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('finalresults', 'wb') as pf:\n",
        "    pickle.dump(finalresults, pf)\n",
        "pf.close()"
      ],
      "metadata": {
        "id": "xYi3qZjf1RRR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNgbYZ826wnH3QwfhMWVjf/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}